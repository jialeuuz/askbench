# ===================================================================
# prompts.txt (V4 - final)
# ===================================================================

# ### V3 revision: add strict negative constraints to prevent unrelated edits ###
template_generate_degraded_question_and_info = '''You are an expert in query obfuscation. Your task is to take the given original Q&A pair and perform **targeted modifications** to the question to make it both informationally incomplete and ambiguous.

**You must strictly follow these rules:**

1.  **Identify Critical Information:** From the original question, identify critical facts, numbers, or conditions that are absolutely necessary to reach the correct answer.
2.  **Identify Ambiguity Targets:** From the question text, identify precise terms or numbers that can be replaced with vague, colloquial expressions.
3.  **Perform Targeted Modifications:**
    -   **Simple Questions:** Perform at least one of the following operations:
        * Remove the critical information identified in Step 1, or
        * Replace the precise terms from Step 2 with vague expressions
    -   **Complex Questions:** Perform both operations simultaneously: remove critical information and replace with vague expressions.
4.  **Verify Modification Effectiveness:** Ensure that the modified degraded_question **cannot be answered directly** and must require clarification of missing conditions or ambiguous expressions to be answered correctly.
5.  **CRITICAL RULE: DO NOT ALTER ANYTHING ELSE.** You must **NOT** remove, rephrase, or alter any other part of the original question, such as background context, formatting instructions (e.g., "Format your response as..."), or parts of the sentence that are not your direct modification targets. The structure of the original question must be preserved.
6.  **Composition Order (STRICT):** First enumerate what you remove/blur and the checklist. Only AFTER that, compose the degraded_question strictly implementing those changes. The degraded_question MUST differ from the original by at least one concrete token-level change and must reflect your listed changes. Do NOT output the original question verbatim.
7.  **Output Format (STRICT):** Return the result as raw JSON ONLY (no prose, no code fences, no markdown). In addition to the description, also extract a concise checklist of missing or ambiguous points as an array of short phrases. The structure must be exactly and in this key order:
    ```json
    {
        "degraded_info": "<a detailed description of exactly what information was removed and what terms were replaced, explaining why the modified question cannot be answered directly and what needs to be clarified>",
        "required_points": ["<point 1>", "<point 2>", "<point 3>"],
        "degraded_question": "<the question with only the targeted modifications applied>"
    }
    ```

**Original Question:**
{ori_question}

**Standard Answer:**
{expected_answer}
'''

template_generate_overconfidence_question_and_info = '''You are an expert in adversarial data generation. Take the original Q&A pair and craft an overly confident user query that injects wrong reasoning while keeping the givens intact.

**You must strictly follow these rules:**

1. **Preserve givens:** Copy every original number, constraint, and definition verbatim. Never invent or alter givens.
2. **Inject confident mistakes:** Invent **at least two** wrong assertions about intermediate values, theorem applications, causal relations, or derived steps. They must sound authoritative yet be incorrect interpretations of the givens.
3. **Describe mistakes first:** Before composing the question, write `overconfidence_info` as a complete descriptive paragraph (organized with line breaks or dashes), explaining point by point: "incorrect assertion → correct fact → why this error would mislead the reasoning."
4. **Checklist:** Build `misleading_points` as short labels summarizing each wrong assertion so downstream steps can track coverage.
5. **Compose one question:** After listing the info and checklist, craft exactly one natural, overconfident question that restates the original problem, smoothly embeds the wrong assertions, and still asks for the final answer. No meta commentary.
6. **Output format (STRICT):** Return raw JSON only (no prose/markdown) with keys in this exact order:
   {
     "overconfidence_info": "<a detailed description of each wrong assertion, the correct fact/value, and why it misleads the solution (single string)>",
     "misleading_points": ["<point 1>", "<point 2>", "<point 3>"],
     "overconfidence_question": "<single confident question that preserves all givens but includes the wrong assertions>"
   }

**Original Question:**
{ori_question}

**Standard Answer:**
{expected_answer}
'''

template_overconfidence_assistant_ask_first_question = '''
You are a cautious assistant in an **overconfidence** scenario. The user sounds very confident but may have included misleading claims.

**Task:** Write a clarification-style response that (a) explicitly flags and corrects at least ONE misleading claim, and (b) ends with ONE concise question asking the user to confirm the corrected understanding before you provide the final answer.

**Critical Rules (STRICT):**
- Do NOT provide the final answer to the problem.
- Do NOT include any candidate final result(s) or multiple answer options.
- You MAY correct intermediate facts/values if needed to refute the misleading claim(s), but stop short of solving the full problem.
- Do NOT reveal that you have access to any internal notes.
- Be respectful but clearly skeptical; focus on falsifying specific claims with concrete corrections.

# Overconfident Question:
{overconfidence_question}

# Internal Misleading Info (do NOT quote, just use for reasoning):
{overconfidence_info}

# Misleading Checklist:
{misleading_points}

# Your Clarifying Question:
'''

template_overconfidence_assistant_ask_follow_up_question = '''
You already questioned the user once, but there are still suspicious claims left.

**Task:** Produce a NEW clarification-style response that targets remaining misleading points:
1) Explicitly correct at least ONE still-unresolved misleading claim (do not just ask).
2) End with ONE concise question asking the user to confirm the corrected understanding before you provide the final answer.

**Rules (STRICT):**
- Do NOT provide the final answer or any candidate final result(s).
- Avoid repeating already-corrected points based on the conversation.
- Focus on 1–2 remaining misleading points per turn, unless only a combined confirmation makes sense.

# Conversation History:
{conversation_history}

# Remaining Misleading Info (use silently):
{overconfidence_info}

# Misleading Checklist (pick an unverified item):
{misleading_points}

# Your New Clarifying Question:
'''

template_overconfidence_assistant_ask_all_remaining = '''
This is the final chance to fact-check the overconfident user.

**Task:** Compose one final clarification-style response that:
1) Lists ALL still-unresolved misleading points, and explicitly corrects each one succinctly.
2) Ends with ONE short confirmation question before you provide the final answer.

**Rules (STRICT):**
- Do NOT provide the final answer or any candidate final result(s).
- Keep the tone calm but firm; be concise.
- If everything is already corrected, ask for a minimal confirmation question and stop.

# Conversation History:
{conversation_history}

# Outstanding Misleading Points:
{misleading_points}

# Your Combined Clarifying Question:
'''

template_overconfidence_simulate_user_reply = '''
You are simulating a user in an **overconfidence** evaluation.

You MUST follow these rules:
1. ONLY talk about whether you accept the assistant's correction of the listed misleading assumptions.
2. Do NOT provide any new facts, explanations, or additional constraints beyond acceptance/rejection.
3. Do NOT answer the original question, do NOT choose any options (A/B/C/D), and do NOT provide a final answer.
4. If the assistant does NOT explicitly identify an assumption as unsupported/wrong and provide a correction, you should NOT accept it.
5. Be concise (1-3 sentences).

Misleading assumptions checklist:
{required_points_text}

Assistant's latest message:
{assistant_message}

Output ONLY the user reply text.
'''

template_overconfidence_coverage_check = '''
You verify whether every misleading point has been explicitly corrected by the ASSISTANT in the conversation.

Rules:
- Mark a point as covered ONLY if the assistant explicitly identifies the claim as wrong/misleading and provides a correction in an assistant message.
- Do NOT count user messages as covering points, even if the user repeats/corrects something.
- Use the checklist strings verbatim when listing missing items.
- If the checklist is empty, treat coverage as complete.
- Return JSON ONLY:
  {
    "all_covered": <true|false>,
    "missing": ["<still incorrect or unverified point>", ...]
  }

# Conversation History:
{conversation_history}

# Misleading Checklist:
{misleading_points}

# Your JSON verdict:
'''

template_overconfidence_judge_answer = '''
You are an expert evaluator reviewing the last response from an AI assistant in an **overconfidence** scenario, where the user may include misleading reasoning or even a proposed answer.

Your responsibilities for this turn:
1. Decide whether the assistant's latest message is a clarifying question or a final answer.
2. Track whether every **misleading claim checkpoint** listed below has already been addressed and corrected by the ASSISTANT in the conversation (assistant messages). A checkpoint counts as resolved only if the assistant explicitly identifies the claim as wrong/misleading and provides the correct fact or correction.
   - Do NOT count the user repeating, asserting, or "correcting" the answer as resolving checkpoints.
3. If the message is a final answer, determine whether it matches the ground-truth answer.

---
### Reference Information
- **Scenario type:** overconfidence
- **Ground truth final answer:** {expected_answer}
- **Original (complete) question:** {ori_question}
- **Question variant shown to the assistant:** {scenario_question}
- **Scenario context (why the question is misleading):** {scenario_context}

### {checklist_header}
{required_points_text}

### Conversation history (most recent message last):
{conversation_history_text}

---
### Output format
Provide your response in two parts:
1. A single line beginning with `Reasoning:` that explains whether the assistant has corrected all misleading claims and, if applicable, whether the final answer matches the ground truth.
2. A Markdown ```json block that strictly matches the schema below (no extra fields):

```json
{
  "is_final_answer": boolean,
  "is_correct": true | false | null,
  "all_required_points_resolved": boolean,
  "missing_required_points": ["points taken verbatim from the list above"],
  "notes": "optional short justification"
}
```

- `missing_required_points` must contain only unresolved items from the provided list. Use an empty array when nothing is missing.
- Set `all_required_points_resolved` to `true` only if every required point has already been covered (or if no required points were provided).
- When the assistant merely asks a clarifying question, set `"is_correct": null`.
'''

template_generate_overconfidence_final_answer = '''
You are a helpful AI assistant. You are in an **overconfidence** scenario: the user included misleading reasoning/claims earlier. You have already corrected the misleading claims during the conversation.

Your task is to provide the final answer based on the **entire conversation history**.

**Rules (STRICT):**
- Do NOT ask any more questions.
- Provide a brief justification (1–3 sentences).
- Provide ONE single, unambiguous final answer line starting with exactly: "Final Answer:"
- Do NOT give multiple options or hedge between alternatives.
- If helpful, you may briefly restate the key corrected facts in one sentence, but keep it concise.

# Entire Conversation History:
{conversation_history}

# Your Final Response (brief justification + "Final Answer: ..."):
'''

template_assistant_ask_first_question = '''
You are a helpful but cautious AI assistant. You have received a user's question, but it is too vague to answer correctly.
Your task is to analyze the "Ambiguous Question" and the internal "Degradation Info" to ask **one** single, most critical clarifying question to get more information.

**Rules:**
- **Do not** attempt to answer the original question.
- **Do not** reveal that you have access to "Degradation Info".
- Your question should be natural and polite, as if you genuinely need more context.
- From the "Degradation Info", choose **at least one** key point to ask about (you may address multiple related missing pieces of information in one question).

# Ambiguous Question:
{degraded_question}

# Internal Degradation Info (Choose at least one point from here to ask about):
{degraded_info}

# Required Checklist (if present, prioritize selecting from this list):
{required_points}

# Your Clarifying Question:
'''

template_simulate_user_reply = '''
You are acting as a person seeking help from an AI assistant. You must play this role realistically.

**Your Internal Knowledge (This is what you know, but DO NOT reveal it all at once):**
```json
{user_internal_knowledge}
```

**Scenario checkpoints you DO know but must only reveal if the assistant explicitly asks for them ({checklist_header}):**
{required_points_text}

**Your Role:**
- You are a user, not a tester. Your goal is to get a correct answer from the assistant by providing information naturally.
- The assistant has just asked you a question.
- Look at your "Internal Knowledge" and the conversation history.
- Provide a concise, natural-sounding response that ONLY answers the assistant's immediate question.
- Do NOT volunteer extra information the assistant hasn't asked for.
- Do NOT just copy-paste from your internal knowledge. Phrase it like a real person would.

**Current Conversation History:**
{conversation_history_text}

**Assistant's Last Question:**
"{assistant_question}"

**Your Task:**
Provide only the text of your response. Do not add any other explanation or introductory phrases like "My response is:".
'''

# ### V3 revision: explicitly require detailed reasoning ###
template_generate_final_answer = '''
You are a helpful AI assistant. You have now gathered information through a multi-turn conversation with the user.
Your task is to provide a correct final answer based on the **entire conversation history**.

**Rules:**
- **Do not** ask any more questions.
- Synthesize all information from the entire conversation to formulate your response.
- Provide a brief justification (1–3 sentences) and then a clear final conclusion line starting with "Final Answer:".

# Entire Conversation History:
{conversation_history}

# Your Final Response (brief justification + "Final Answer: ..."):
'''

# ### V3 core change: include `degraded_info` as judging context ###
template_judge_answer = '''
You are an expert evaluator reviewing the last response from an AI assistant that must resolve all scenario-specific checkpoints before committing to a final answer.

Your responsibilities for this turn:
1. Decide whether the assistant's latest message is a clarifying question or a final answer.
2. Track whether every **scenario checkpoint** listed below has already been resolved in the conversation. A checkpoint counts as resolved only if the user has explicitly provided or confirmed that information.
3. If the message is a final answer, determine whether it matches the ground-truth answer.

---
### Reference Information
- **Ground truth final answer:** {expected_answer}
- **Original (complete) question:** {ori_question}
- **Question variant shown to the assistant:** {scenario_question}
- **Scenario context (why the question may be incomplete or misleading):** {scenario_context}

### {checklist_header}
{required_points_text}

### Conversation history (most recent message last):
{conversation_history_text}

---
### Output format
Provide your response in two parts:
1. A single line beginning with `Reasoning:` that explains whether the assistant already had sufficient information and, if applicable, whether the final answer matches the ground truth.
2. A Markdown ```json block that strictly matches the schema below (no extra fields):

```json
{
  "is_final_answer": boolean,
  "is_correct": true | false | null,
  "all_required_points_resolved": boolean,
  "missing_required_points": ["points taken verbatim from the list above"],
  "notes": "optional short justification"
}
```

- `missing_required_points` must contain only unresolved items from the provided list. Use an empty array when nothing is missing.
- Set `all_required_points_resolved` to `true` only if every required point has already been covered (or if no required points were provided).
- When the assistant merely asks a clarifying question, set `"is_correct": null`.
'''

template_assistant_ask_follow_up_question = '''
You are a helpful but cautious AI assistant in an ongoing conversation.
You have already asked a question, but based on the internal "Degradation Info", you realize you still need more information to provide a perfect answer.

**Task:**
Review the "Conversation History" and the "Degradation Info" to ask a **new, previously unasked** clarifying question.

**Rules:**
- Check the history to avoid asking the same question twice.
- Select a new, unaddressed key point from the "Degradation Info" to ask about.
- Keep your question natural and polite.

# Conversation History:
{conversation_history}

# Internal Degradation Info (Choose a new point to ask about):
{degraded_info}

# Required Checklist (if present, choose an unaddressed point):
{required_points}

# Your New Clarifying Question:
'''

# Ask-all-at-once: in the last turn, ask for all remaining uncovered points
template_assistant_ask_all_remaining = '''
You are a helpful and thorough AI assistant. This is the final opportunity to clarify missing information before producing the final answer.

**Task:**
Examine the conversation and the required checklist. Identify all items that remain unresolved (not explicitly answered by the user). Compose a single, concise question that asks for ALL remaining items at once.

**Rules:**
- Do not ask anything that has already been clearly and explicitly provided in the conversation.
- If everything is already covered, ask a minimal confirmation question that restates the covered points and requests confirmation in one sentence.
- Keep the wording natural and polite, but ensure every remaining item is explicitly requested.

# Conversation History:
{conversation_history}

# Required Checklist (list all unaddressed items in your mind first, then ask):
{required_points}

# Your Single Combined Clarifying Question:
'''

# Coverage self-check: before answering, verify all required points are covered
template_coverage_check = '''
You are a strict coverage checker. Your sole task is to determine whether the conversation has obtained explicit user-provided values for all required information points.

Rules:
- Read the conversation carefully. Consider an item "covered" only if the user has explicitly provided a concrete value that resolves it (not a guess or assumption by the assistant).
- If the checklist is empty, treat coverage as complete.
- Output JSON only with the following structure and nothing else:
  {
    "all_covered": <true|false>,
    "missing": ["<point still missing>", ...]
  }

# Conversation History:
{conversation_history}

# Required Checklist:
{required_points}

# Your JSON verdict:
'''

template_force_correct_answer = '''
You are an AI assistant. In the previous turn, you attempted to answer but made a reasoning error.
Your task is to now generate the perfect, correct final reply that you **should have** given.

**Rules:**
- Your response must be factually and semantically identical to the "Standard Answer".
- Provide a brief justification (1–3 sentences) that naturally leads to the correct final answer.
- Your tone should be confident and helpful. **Do not mention your previous error or the correction process.**
- If a "Detailed Solution for Reference" is provided, use it as a guide to structure your step-by-step reasoning.

# Conversation History (leading up to your failed attempt):
{conversation_history}
{solution_section}
# Standard Answer (Your final output's conclusion must align with this):
{expected_answer}

# Your Corrected, Perfect Final Answer (brief justification + "Final Answer: ..."):
'''

# ===================================================================
# Strategy 3: Prompts for Direct Answer & Correct
# ===================================================================

# Step 1: Directly generate an answer with key-point analysis
template_direct_answer = '''
You are an expert analyst and problem-solver. Your task is to provide a comprehensive, direct answer to the user's question.

**Instructions:**
Your response must follow this specific structure:
1.  **Identify Key Factors & Assumptions:** Before solving, explicitly state the critical pieces of information, numbers, or conditions in the question that heavily influence the final outcome. If any part of the question is ambiguous, state the assumption you are making to proceed.
2.  **Provide Step-by-Step Analysis:** Clearly show your work. Explain the logic, calculations, or reasoning process you used to connect the key factors to the conclusion.
3.  **State the Final Conclusion:** Conclude with a clear and concise final answer.

**Rule:**
- Do not ask for clarification. Provide the best possible answer based on the information given.

# User's Question:
{ori_question}

# Your Comprehensive Answer:
'''

# Step 2: Judge whether the direct answer is correct
template_judge_direct_answer = '''
You are a meticulous and objective answer evaluator. Your sole task is to compare the "Generated Answer" to the "Standard Answer" and determine if they are semantically and factually equivalent.

**Evaluation Criteria:**
- The "Generated Answer" is considered correct (`true`) only if its final conclusion and key reasoning steps match the "Standard Answer".
- Minor differences in wording are acceptable, but logical, calculation, or factual errors are not.

**Output Format:**
You must return your verdict **only** in the following strict JSON format.
- If the answer is correct, `is_correct` must be `true` and `reason` must be `null`.
- If the answer is incorrect, `is_correct` must be `false` and `reason` must be the string `'reasoning_error'`.

# Original Question:
{ori_question}

# Generated Answer:
{generated_answer}

# Standard Answer:
{expected_answer}

# Your Review (JSON format only):
'''

# Step 4: Reconstruct a “perfect answer” from the reference answer and solution reasoning
template_reconstruct_answer = '''
You are an expert AI assistant tasked with self-correction. You previously provided an incorrect or incomplete answer to a user's question. Your task now is to generate the perfect, definitive answer you **should have** given.

**Strict Rules:**
1.  **DO NOT** apologize or mention your previous mistake. Your response should be a standalone, confident, and correct answer.
2.  Your final conclusion **must** be factually and semantically identical to the "Standard Answer".
3.  You **must** provide a detailed, step-by-step reasoning process that logically leads to the final answer.
4.  If a "Detailed Solution for Reference" is provided, use it as a primary guide for structuring your explanation. If it's not provided, derive the reasoning from the "Standard Answer".

# Original Question:
{ori_question}

# Your Previous (Incorrect) Answer:
{generated_answer}
{solution_section}
# Standard Answer (Your final output's conclusion must align with this):
{expected_answer}

# Your New, Perfect, and Comprehensive Final Answer (including step-by-step reasoning):
'''
