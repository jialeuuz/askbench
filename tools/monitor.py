#!/usr/bin/env python3
"""
è®­ç»ƒæ—¥å¿—å¯è§†åŒ– Gradio åº”ç”¨
ç”¨æ³•: python training_monitor_gradio.py
ç„¶ååœ¨æµè§ˆå™¨æ‰“å¼€æ˜¾ç¤ºçš„URL
"""

import gradio as gr
import matplotlib.pyplot as plt
import matplotlib
matplotlib.use('Agg')
import numpy as np
import json
from pathlib import Path
from typing import List, Dict, Tuple
import pandas as pd
import warnings


# è®¾ç½®matplotlibæ ·å¼
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10
plt.style.use('seaborn-v0_8-darkgrid')
plt.rcParams['axes.unicode_minus'] = False

# ç¦ç”¨è­¦å‘Š
warnings.filterwarnings('ignore', category=UserWarning)

def scan_training_tasks() -> List[str]:
    """æ‰«ææ‰€æœ‰è®­ç»ƒä»»åŠ¡ç›®å½•"""
    if not ROOT_DIR.exists():
        return []
    
    tasks = []
    for item in ROOT_DIR.iterdir():
        if item.is_dir():
            rollout_dir = item / "rollout_log"
            if rollout_dir.exists():
                tasks.append(item.name)
    
    return sorted(tasks)

def load_rollout_data(task_name: str) -> pd.DataFrame:
    """åŠ è½½rolloutæ•°æ®"""
    rollout_dir = ROOT_DIR / task_name / "rollout_log"
    
    data = []
    for jsonl_file in sorted(rollout_dir.glob("*.jsonl")):
        with open(jsonl_file, 'r') as f:
            for line in f:
                try:
                    item = json.loads(line)
                    data.append({
                        'step': item.get('step'),
                        'score': item.get('score'),
                        'acc': item.get('acc'),
                        'file': jsonl_file.stem
                    })
                except:
                    continue
    
    df = pd.DataFrame(data)
    df = df.dropna(subset=['score'])
    return df

def load_validation_data(task_name: str) -> pd.DataFrame:
    """åŠ è½½validationæ•°æ® - ä»æ–‡ä»¶åæå–step"""
    val_dir = ROOT_DIR / task_name / "validation_log"
    
    if not val_dir.exists():
        return pd.DataFrame()
    
    data = []
    for jsonl_file in sorted(val_dir.glob("*.jsonl")):
        # ä»æ–‡ä»¶åæå–step
        try:
            file_step = int(jsonl_file.stem)
        except ValueError:
            print(f"âš ï¸  è·³è¿‡æ— æ³•è§£æçš„æ–‡ä»¶: {jsonl_file.name}")
            continue
            
        with open(jsonl_file, 'r') as f:
            for line in f:
                try:
                    item = json.loads(line)
                    data.append({
                        'step': file_step,
                        'score': item.get('score'),
                        'reward': item.get('reward'),
                        'acc': item.get('acc')
                    })
                except:
                    continue
    
    if data:
        df = pd.DataFrame(data)
        df_agg = df.groupby('step').agg({
            'score': 'mean',
            'reward': 'mean',
            'acc': 'mean'
        }).reset_index()
        return df_agg
    
    return pd.DataFrame()

def recommend_best_checkpoint(task_name: str, df: pd.DataFrame, val_df: pd.DataFrame = None, save_interval: int = 20) -> str:
    """æ¨èæœ€ä½³checkpointï¼ˆåªè€ƒè™‘å®é™…ä¿å­˜çš„checkpointï¼‰"""
    recommendation = []
    recommendation.append("=" * 60)
    recommendation.append("ğŸ† æ¨¡å‹æ£€æŸ¥ç‚¹æ¨è")
    recommendation.append("=" * 60)
    recommendation.append("")
    
    df_agg = df.groupby('step').agg({
        'score': ['mean', 'std', 'count']
    }).reset_index()
    df_agg.columns = ['step', 'score_mean', 'score_std', 'count']
    
    # âœ… åªä¿ç•™èƒ½è¢«save_intervalæ•´é™¤çš„æ­¥æ•°ï¼ˆå®é™…ä¿å­˜çš„checkpointï¼‰
    df_agg = df_agg[df_agg['step'] % save_interval == 0].copy()
    
    if df_agg.empty:
        recommendation.append("âš ï¸  æœªæ‰¾åˆ°ç¬¦åˆä¿å­˜é—´éš”çš„checkpointæ•°æ®")
        recommendation.append(f"   å½“å‰ä¿å­˜é—´éš”: æ¯ {save_interval} æ­¥")
        recommendation.append("")
        recommendation.append("=" * 60)
        return "\n".join(recommendation)
    
    recommendation.append(f"â„¹ï¸  Checkpointä¿å­˜é—´éš”: æ¯ {save_interval} æ­¥")
    recommendation.append(f"   å¯ç”¨çš„checkpointæ­¥æ•°: {sorted(df_agg['step'].tolist())}")
    recommendation.append("")
    
    # è®¡ç®—ç»¼åˆå¾—åˆ†ï¼ˆè€ƒè™‘å‡å€¼å’Œç¨³å®šæ€§ï¼‰
    df_agg['composite_score'] = df_agg['score_mean'] - 0.2 * df_agg['score_std']
    
    # ç­–ç•¥1ï¼šæœ€é«˜å¹³å‡åˆ†æ•°
    best_avg_step = df_agg.loc[df_agg['score_mean'].idxmax()]
    
    # ç­–ç•¥2ï¼šæœ€é«˜ç»¼åˆå¾—åˆ†ï¼ˆå¹³è¡¡å‡å€¼å’Œç¨³å®šæ€§ï¼‰
    best_composite_step = df_agg.loc[df_agg['composite_score'].idxmax()]
    
    # ç­–ç•¥3ï¼šæœ€åä¸€ä¸ªcheckpoint
    last_step = df_agg.iloc[-1]
    
    recommendation.append("ğŸ“Š å€™é€‰æ£€æŸ¥ç‚¹åˆ†æï¼š")
    recommendation.append("")
    
    recommendation.append("1ï¸âƒ£  æœ€é«˜å¹³å‡åˆ†æ•°æ¨¡å‹ï¼š")
    recommendation.append(f"   Step: {int(best_avg_step['step'])}")
    recommendation.append(f"   å¹³å‡åˆ†æ•°: {best_avg_step['score_mean']:.4f}")
    recommendation.append(f"   æ ‡å‡†å·®:   {best_avg_step['score_std']:.4f}")
    recommendation.append(f"   æ ·æœ¬æ•°:   {int(best_avg_step['count'])}")
    recommendation.append("")
    
    recommendation.append("2ï¸âƒ£  æœ€ç¨³å®šé«˜åˆ†æ¨¡å‹ï¼š")
    recommendation.append(f"   Step: {int(best_composite_step['step'])}")
    recommendation.append(f"   å¹³å‡åˆ†æ•°: {best_composite_step['score_mean']:.4f}")
    recommendation.append(f"   æ ‡å‡†å·®:   {best_composite_step['score_std']:.4f}")
    recommendation.append(f"   ç»¼åˆå¾—åˆ†: {best_composite_step['composite_score']:.4f}")
    recommendation.append("")
    
    recommendation.append("3ï¸âƒ£  æœ€æ–°æ¨¡å‹ï¼š")
    recommendation.append(f"   Step: {int(last_step['step'])}")
    recommendation.append(f"   å¹³å‡åˆ†æ•°: {last_step['score_mean']:.4f}")
    recommendation.append(f"   æ ‡å‡†å·®:   {last_step['score_std']:.4f}")
    recommendation.append("")
    
    # å¦‚æœæœ‰éªŒè¯é›†æ•°æ®ï¼ŒåŠ å…¥éªŒè¯é›†è¡¨ç°
    recommended_from_val = None
    if val_df is not None and not val_df.empty:
        # âœ… åŒæ ·åªè€ƒè™‘ä¿å­˜çš„checkpoint
        val_df_filtered = val_df[val_df['step'] % save_interval == 0].copy()
        
        if not val_df_filtered.empty:
            recommendation.append("4ï¸âƒ£  éªŒè¯é›†æœ€ä½³æ¨¡å‹ï¼š")
            best_val_step = val_df_filtered.loc[val_df_filtered['score'].idxmax()]
            recommended_from_val = int(best_val_step['step'])
            recommendation.append(f"   Step: {recommended_from_val}")
            recommendation.append(f"   éªŒè¯åˆ†æ•°: {best_val_step['score']:.4f}")
            if 'acc' in val_df_filtered.columns:
                recommendation.append(f"   éªŒè¯å‡†ç¡®ç‡: {best_val_step['acc']:.4f}")
            recommendation.append("")
    
    recommendation.append("=" * 60)
    recommendation.append("ğŸ¯ æœ€ç»ˆæ¨èï¼š")
    recommendation.append("=" * 60)
    recommendation.append("")
    
    # å†³ç­–é€»è¾‘
    if recommended_from_val is not None:
        # å¦‚æœæœ‰éªŒè¯é›†ï¼Œä¼˜å…ˆè€ƒè™‘éªŒè¯é›†è¡¨ç°
        recommended_step = recommended_from_val
        reason = "éªŒè¯é›†è¡¨ç°æœ€ä½³"
        
        recommendation.append(f"âœ… æ¨èä½¿ç”¨ Step {recommended_step} çš„æ¨¡å‹")
        recommendation.append(f"   æ¨èç†ç”±: {reason}")
        
        val_perf = val_df[val_df['step'] == recommended_step]
        if not val_perf.empty:
            recommendation.append(f"   éªŒè¯åˆ†æ•°: {val_perf['score'].values[0]:.4f}")
        
        # æ£€æŸ¥è®­ç»ƒé›†å¯¹åº”çš„è¡¨ç°
        train_perf = df_agg[df_agg['step'] == recommended_step]
        if not train_perf.empty:
            recommendation.append(f"   è®­ç»ƒåˆ†æ•°: {train_perf['score_mean'].values[0]:.4f}")
        
    else:
        # æ²¡æœ‰éªŒè¯é›†ï¼Œæ ¹æ®è®­ç»ƒé›†å†³ç­–
        if best_avg_step['step'] == best_composite_step['step']:
            recommended_step = int(best_avg_step['step'])
            reason = "è®­ç»ƒé›†å¹³å‡åˆ†æ•°æœ€é«˜ä¸”ç¨³å®š"
        else:
            # å¦‚æœç›¸å·®ä¸å¤§ï¼Œæ¨èç»¼åˆå¾—åˆ†æœ€é«˜çš„ï¼ˆæ›´ç¨³å®šï¼‰
            if best_avg_step['score_mean'] - best_composite_step['score_mean'] < 0.05:
                recommended_step = int(best_composite_step['step'])
                reason = "ç»¼åˆè€ƒè™‘åˆ†æ•°å’Œç¨³å®šæ€§"
            else:
                recommended_step = int(best_avg_step['step'])
                reason = "è®­ç»ƒé›†å¹³å‡åˆ†æ•°æ˜¾è‘—æœ€é«˜"
        
        recommendation.append(f"âœ… æ¨èä½¿ç”¨ Step {recommended_step} çš„æ¨¡å‹")
        recommendation.append(f"   æ¨èç†ç”±: {reason}")
        
        rec_perf = df_agg[df_agg['step'] == recommended_step]
        recommendation.append(f"   å¹³å‡åˆ†æ•°: {rec_perf['score_mean'].values[0]:.4f}")
        recommendation.append(f"   æ ‡å‡†å·®:   {rec_perf['score_std'].values[0]:.4f}")
    
    recommendation.append("")
    
    # è¡¥å……å»ºè®®
    recommendation.append("ğŸ’¡ è¡¥å……å»ºè®®ï¼š")
    
    # æ£€æŸ¥æ˜¯å¦æœ‰è¿‡æ‹Ÿåˆè¿¹è±¡
    if val_df is not None and not val_df.empty:
        val_df_filtered = val_df[val_df['step'] % save_interval == 0]
        if not val_df_filtered.empty:
            train_val_gap = df_agg['score_mean'].mean() - val_df_filtered['score'].mean()
            if train_val_gap > 0.2:
                recommendation.append("   âš ï¸  æ£€æµ‹åˆ°è®­ç»ƒé›†å’ŒéªŒè¯é›†å·®è·è¾ƒå¤§ï¼Œå»ºè®®:")
                recommendation.append("      - è€ƒè™‘ä½¿ç”¨è¾ƒæ—©æœŸçš„checkpoint")
                recommendation.append("      - å…³æ³¨éªŒè¯é›†è¡¨ç°è€Œéè®­ç»ƒé›†")
            else:
                recommendation.append("   âœ… è®­ç»ƒéªŒè¯ä¸€è‡´æ€§è‰¯å¥½ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›å¥½")
    
    # æ£€æŸ¥è®­ç»ƒè¶‹åŠ¿
    if len(df_agg) > 1:
        score_trend = df_agg['score_mean'].iloc[-1] - df_agg['score_mean'].iloc[0]
        if score_trend > 0.1:
            recommendation.append("   ğŸ“ˆ è®­ç»ƒä»åœ¨æŒç»­æ”¹è¿›ä¸­ï¼Œå¯ä»¥è€ƒè™‘:")
            recommendation.append("      - ç»§ç»­è®­ç»ƒæ›´å¤šæ­¥æ•°")
            recommendation.append("      - æˆ–ä½¿ç”¨å½“å‰æœ€ä½³checkpoint")
        elif score_trend < -0.1:
            recommendation.append("   ğŸ“‰ åæœŸè®­ç»ƒæœ‰ä¸‹é™è¶‹åŠ¿ï¼Œå»ºè®®:")
            recommendation.append("      - ä½¿ç”¨ä¸­æœŸè¡¨ç°æœ€å¥½çš„checkpoint")
            recommendation.append("      - æ£€æŸ¥è®­ç»ƒé…ç½®å’Œæ•°æ®è´¨é‡")
    
    # ç¨³å®šæ€§å»ºè®®
    if df_agg['score_std'].mean() > 1.0:
        recommendation.append("   ğŸ”„ æ¨¡å‹è¾“å‡ºæ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®:")
        recommendation.append("      - ä¼˜å…ˆé€‰æ‹©æ ‡å‡†å·®è¾ƒå°çš„checkpoint")
        recommendation.append("      - è€ƒè™‘è°ƒæ•´é‡‡æ ·æ¸©åº¦æˆ–å…¶ä»–è§£ç å‚æ•°")
    
    # æ˜¾ç¤ºæ‰€æœ‰å¯ç”¨checkpointçš„æ’å
    recommendation.append("")
    recommendation.append("ğŸ“‹ æ‰€æœ‰å¯ç”¨Checkpointæ’åï¼ˆæŒ‰å¹³å‡åˆ†æ•°ï¼‰ï¼š")
    df_sorted = df_agg.sort_values('score_mean', ascending=False)
    for idx, row in df_sorted.head(5).iterrows():
        rank_symbol = "ğŸ‘‘" if row['step'] == recommended_step else "  "
        recommendation.append(f"   {rank_symbol} Step {int(row['step']):>4}: {row['score_mean']:>8.4f} (std: {row['score_std']:.4f})")
    
    recommendation.append("")
    recommendation.append("=" * 60)
    recommendation.append("ğŸ“ æ¨èæ¨¡å‹è·¯å¾„ï¼š")
    recommendation.append(f"   {ROOT_DIR / task_name / f'checkpoint-{recommended_step}'}")
    recommendation.append("=" * 60)
    
    return "\n".join(recommendation)

def analyze_score_trend(df: pd.DataFrame, val_df: pd.DataFrame = None) -> str:
    """åˆ†æScoreè¶‹åŠ¿"""
    analysis = []
    analysis.append("=" * 60)
    analysis.append("ğŸ“ˆ åˆ†æ•°è¶‹åŠ¿åˆ†æ")
    analysis.append("=" * 60)
    analysis.append("")
    
    df_agg = df.groupby('step')['score'].agg(['mean', 'std']).reset_index()
    
    first_score = df_agg['mean'].iloc[0]
    last_score = df_agg['mean'].iloc[-1]
    max_score = df_agg['mean'].max()
    min_score = df_agg['mean'].min()
    
    analysis.append(f"ğŸ¯ å…³é”®æŒ‡æ ‡:")
    analysis.append(f"   åˆå§‹åˆ†æ•°: {first_score:>8.4f}")
    analysis.append(f"   æœ€ç»ˆåˆ†æ•°: {last_score:>8.4f}")
    analysis.append(f"   æœ€é«˜åˆ†æ•°: {max_score:>8.4f}")
    analysis.append(f"   æœ€ä½åˆ†æ•°: {min_score:>8.4f}")
    analysis.append("")
    
    improvement = last_score - first_score
    improvement_pct = (improvement / abs(first_score) * 100) if first_score != 0 else 0
    
    analysis.append(f"ğŸ“Š æ•´ä½“è¶‹åŠ¿:")
    analysis.append(f"   åˆ†æ•°å˜åŒ–: {improvement:>+8.4f}")
    analysis.append(f"   å˜åŒ–ç‡:   {improvement_pct:>+8.1f}%")
    
    if improvement > 0.1:
        conclusion = "âœ… è®­ç»ƒæ•ˆæœè‰¯å¥½ï¼Œåˆ†æ•°æŒç»­æå‡"
    elif improvement > 0:
        conclusion = "ğŸŸ¢ è®­ç»ƒç¨³æ­¥è¿›è¡Œï¼Œåˆ†æ•°ç•¥æœ‰æå‡"
    elif improvement > -0.1:
        conclusion = "ğŸŸ¡ åˆ†æ•°åŸºæœ¬ç¨³å®šï¼Œå»ºè®®è§‚å¯Ÿåç»­è¶‹åŠ¿"
    else:
        conclusion = "âš ï¸  åˆ†æ•°ä¸‹é™ï¼Œå»ºè®®æ£€æŸ¥è®­ç»ƒé…ç½®"
    
    analysis.append(f"   ç»“è®º: {conclusion}")
    analysis.append("")
    
    volatility = df_agg['std'].mean()
    analysis.append(f"ğŸ“‰ æ³¢åŠ¨æ€§åˆ†æ:")
    analysis.append(f"   å¹³å‡æ ‡å‡†å·®: {volatility:.4f}")
    
    if volatility < 0.5:
        stability = "ç¨³å®šæ€§å¥½"
    elif volatility < 1.0:
        stability = "ç¨³å®šæ€§ä¸­ç­‰"
    else:
        stability = "æ³¢åŠ¨è¾ƒå¤§ï¼Œå»ºè®®æ£€æŸ¥æ•°æ®è´¨é‡"
    analysis.append(f"   è¯„ä¼°: {stability}")
    analysis.append("")
    
    if val_df is not None and not val_df.empty:
        val_mean = val_df['score'].mean()
        train_mean = df_agg['mean'].mean()
        gap = train_mean - val_mean
        
        analysis.append(f"ğŸ” éªŒè¯é›†å¯¹æ¯”:")
        analysis.append(f"   è®­ç»ƒé›†å¹³å‡: {train_mean:>8.4f}")
        analysis.append(f"   éªŒè¯é›†å¹³å‡: {val_mean:>8.4f}")
        analysis.append(f"   å·®è·:       {gap:>+8.4f}")
        
        if abs(gap) < 0.1:
            analysis.append(f"   ç»“è®º: âœ… è®­ç»ƒéªŒè¯ä¸€è‡´æ€§å¥½")
        elif gap > 0.2:
            analysis.append(f"   ç»“è®º: âš ï¸  å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        else:
            analysis.append(f"   ç»“è®º: ğŸŸ¢ è¡¨ç°æ­£å¸¸")
    
    analysis.append("")
    analysis.append("=" * 60)
    
    return "\n".join(analysis)

def analyze_score_distribution(df: pd.DataFrame) -> str:
    """åˆ†æScoreåˆ†å¸ƒ"""
    analysis = []
    analysis.append("=" * 60)
    analysis.append("ğŸ“Š åˆ†æ•°åˆ†å¸ƒåˆ†æ")
    analysis.append("=" * 60)
    analysis.append("")
    
    scores = df['score'].values
    
    mean_score = np.mean(scores)
    median_score = np.median(scores)
    std_score = np.std(scores)
    
    analysis.append(f"ğŸ“ˆ åˆ†å¸ƒç‰¹å¾:")
    analysis.append(f"   å‡å€¼:   {mean_score:>8.4f}")
    analysis.append(f"   ä¸­ä½æ•°: {median_score:>8.4f}")
    analysis.append(f"   æ ‡å‡†å·®: {std_score:>8.4f}")
    analysis.append("")
    
    skewness = np.mean((scores - mean_score) ** 3) / (std_score ** 3) if std_score > 0 else 0
    analysis.append(f"ğŸ”„ ååº¦åˆ†æ:")
    analysis.append(f"   ååº¦ç³»æ•°: {skewness:.4f}")
    
    if skewness > 0.5:
        skew_desc = "å³åï¼ˆæ­£åï¼‰ï¼Œå­˜åœ¨è¾ƒå¤šé«˜åˆ†æ ·æœ¬"
    elif skewness < -0.5:
        skew_desc = "å·¦åï¼ˆè´Ÿåï¼‰ï¼Œå­˜åœ¨è¾ƒå¤šä½åˆ†æ ·æœ¬"
    else:
        skew_desc = "æ¥è¿‘å¯¹ç§°åˆ†å¸ƒ"
    analysis.append(f"   ç‰¹å¾: {skew_desc}")
    analysis.append("")
    
    q25 = np.percentile(scores, 25)
    q75 = np.percentile(scores, 75)
    iqr = q75 - q25
    
    analysis.append(f"ğŸ“¦ å››åˆ†ä½æ•°:")
    analysis.append(f"   Q25 (ä¸‹å››åˆ†ä½): {q25:>8.4f}")
    analysis.append(f"   Q75 (ä¸Šå››åˆ†ä½): {q75:>8.4f}")
    analysis.append(f"   IQR (å››åˆ†ä½è·): {iqr:>8.4f}")
    analysis.append("")
    
    lower_bound = q25 - 1.5 * iqr
    upper_bound = q75 + 1.5 * iqr
    outliers = np.sum((scores < lower_bound) | (scores > upper_bound))
    outlier_pct = outliers / len(scores) * 100
    
    analysis.append(f"ğŸ¯ å¼‚å¸¸å€¼æ£€æµ‹:")
    analysis.append(f"   å¼‚å¸¸å€¼æ•°é‡: {outliers} ({outlier_pct:.2f}%)")
    
    if outlier_pct < 5:
        analysis.append(f"   ç»“è®º: âœ… æ•°æ®è´¨é‡è‰¯å¥½")
    elif outlier_pct < 10:
        analysis.append(f"   ç»“è®º: ğŸŸ¡ å­˜åœ¨å°‘é‡å¼‚å¸¸å€¼")
    else:
        analysis.append(f"   ç»“è®º: âš ï¸  å¼‚å¸¸å€¼è¾ƒå¤šï¼Œå»ºè®®æ£€æŸ¥æ•°æ®")
    analysis.append("")
    
    pos_count = np.sum(scores > 0)
    neg_count = np.sum(scores <= 0)
    pos_ratio = pos_count / len(scores) * 100
    
    analysis.append(f"âš–ï¸  æ­£è´Ÿæ ·æœ¬åˆ†å¸ƒ:")
    analysis.append(f"   æ­£æ ·æœ¬: {pos_count} ({pos_ratio:.1f}%)")
    analysis.append(f"   è´Ÿæ ·æœ¬: {neg_count} ({100-pos_ratio:.1f}%)")
    
    if pos_ratio > 60:
        balance = "æ­£æ ·æœ¬å ä¼˜ï¼Œæ¨¡å‹å­¦ä¹ æ–¹å‘è‰¯å¥½"
    elif pos_ratio > 40:
        balance = "æ­£è´Ÿæ ·æœ¬è¾ƒä¸ºå‡è¡¡"
    else:
        balance = "è´Ÿæ ·æœ¬åå¤šï¼Œå»ºè®®å…³æ³¨ç­–ç•¥è´¨é‡"
    analysis.append(f"   è¯„ä¼°: {balance}")
    
    analysis.append("")
    analysis.append("=" * 60)
    
    return "\n".join(analysis)

def analyze_accuracy_trend(df: pd.DataFrame, val_df: pd.DataFrame = None) -> str:
    """åˆ†æå‡†ç¡®ç‡è¶‹åŠ¿"""
    analysis = []
    analysis.append("=" * 60)
    analysis.append("âœ… å‡†ç¡®ç‡è¶‹åŠ¿åˆ†æ")
    analysis.append("=" * 60)
    analysis.append("")
    
    if 'acc' not in df.columns or df['acc'].isna().all():
        analysis.append("âš ï¸  æœªæ‰¾åˆ°å‡†ç¡®ç‡æ•°æ®")
        analysis.append("")
        analysis.append("=" * 60)
        return "\n".join(analysis)
    
    df_agg = df.groupby('step')['acc'].agg(['mean', 'std']).reset_index()
    
    first_acc = df_agg['mean'].iloc[0]
    last_acc = df_agg['mean'].iloc[-1]
    max_acc = df_agg['mean'].max()
    avg_acc = df_agg['mean'].mean()
    
    analysis.append(f"ğŸ¯ å‡†ç¡®ç‡æŒ‡æ ‡:")
    analysis.append(f"   åˆå§‹å‡†ç¡®ç‡: {first_acc:>8.4f}")
    analysis.append(f"   æœ€ç»ˆå‡†ç¡®ç‡: {last_acc:>8.4f}")
    analysis.append(f"   æœ€é«˜å‡†ç¡®ç‡: {max_acc:>8.4f}")
    analysis.append(f"   å¹³å‡å‡†ç¡®ç‡: {avg_acc:>8.4f}")
    analysis.append("")
    
    improvement = last_acc - first_acc
    analysis.append(f"ğŸ“ˆ æå‡æƒ…å†µ:")
    analysis.append(f"   å‡†ç¡®ç‡æå‡: {improvement:>+8.4f}")
    
    if improvement > 0.1:
        conclusion = "âœ… å‡†ç¡®ç‡æ˜¾è‘—æå‡ï¼Œæ¨¡å‹å­¦ä¹ æ•ˆæœå¥½"
    elif improvement > 0.02:
        conclusion = "ğŸŸ¢ å‡†ç¡®ç‡ç¨³æ­¥æå‡"
    elif improvement > -0.02:
        conclusion = "ğŸŸ¡ å‡†ç¡®ç‡åŸºæœ¬ç¨³å®š"
    else:
        conclusion = "âš ï¸  å‡†ç¡®ç‡ä¸‹é™ï¼Œéœ€è¦å…³æ³¨"
    
    analysis.append(f"   ç»“è®º: {conclusion}")
    analysis.append("")
    
    if val_df is not None and not val_df.empty and 'acc' in val_df.columns:
        val_acc_mean = val_df['acc'].mean()
        train_acc_mean = df_agg['mean'].mean()
        gap = train_acc_mean - val_acc_mean
        
        analysis.append(f"ğŸ” è®­ç»ƒéªŒè¯å¯¹æ¯”:")
        analysis.append(f"   è®­ç»ƒé›†å‡†ç¡®ç‡: {train_acc_mean:>8.4f}")
        analysis.append(f"   éªŒè¯é›†å‡†ç¡®ç‡: {val_acc_mean:>8.4f}")
        analysis.append(f"   å·®è·:         {gap:>+8.4f}")
        
        if abs(gap) < 0.05:
            analysis.append(f"   ç»“è®º: âœ… æ³›åŒ–èƒ½åŠ›è‰¯å¥½")
        elif gap > 0.1:
            analysis.append(f"   ç»“è®º: âš ï¸  å¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        else:
            analysis.append(f"   ç»“è®º: ğŸŸ¢ è¡¨ç°æ­£å¸¸")
    
    analysis.append("")
    analysis.append("=" * 60)
    
    return "\n".join(analysis)

def analyze_positive_ratio(df: pd.DataFrame) -> str:
    """åˆ†ææ­£æ ·æœ¬å æ¯”"""
    analysis = []
    analysis.append("=" * 60)
    analysis.append("âš–ï¸  æ­£æ ·æœ¬å æ¯”åˆ†æ")
    analysis.append("=" * 60)
    analysis.append("")
    
    df['is_positive'] = df['score'] > 0
    ratio_df = df.groupby('step')['is_positive'].agg(['sum', 'count']).reset_index()
    ratio_df['ratio'] = ratio_df['sum'] / ratio_df['count'] * 100
    
    first_ratio = ratio_df['ratio'].iloc[0]
    last_ratio = ratio_df['ratio'].iloc[-1]
    avg_ratio = ratio_df['ratio'].mean()
    max_ratio = ratio_df['ratio'].max()
    min_ratio = ratio_df['ratio'].min()
    
    analysis.append(f"ğŸ“Š å æ¯”ç»Ÿè®¡:")
    analysis.append(f"   åˆå§‹å æ¯”: {first_ratio:>6.2f}%")
    analysis.append(f"   æœ€ç»ˆå æ¯”: {last_ratio:>6.2f}%")
    analysis.append(f"   å¹³å‡å æ¯”: {avg_ratio:>6.2f}%")
    analysis.append(f"   æœ€é«˜å æ¯”: {max_ratio:>6.2f}%")
    analysis.append(f"   æœ€ä½å æ¯”: {min_ratio:>6.2f}%")
    analysis.append("")
    
    ratio_change = last_ratio - first_ratio
    analysis.append(f"ğŸ“ˆ å˜åŒ–è¶‹åŠ¿:")
    analysis.append(f"   å æ¯”å˜åŒ–: {ratio_change:>+6.2f}%")
    
    if ratio_change > 10:
        trend = "æ­£æ ·æœ¬å æ¯”æ˜¾è‘—æå‡ï¼Œç­–ç•¥ä¼˜åŒ–æ•ˆæœå¥½"
    elif ratio_change > 5:
        trend = "æ­£æ ·æœ¬å æ¯”ç¨³æ­¥æå‡"
    elif ratio_change > -5:
        trend = "å æ¯”åŸºæœ¬ç¨³å®š"
    else:
        trend = "æ­£æ ·æœ¬å æ¯”ä¸‹é™ï¼Œéœ€è¦å…³æ³¨"
    analysis.append(f"   è¶‹åŠ¿: {trend}")
    analysis.append("")
    
    analysis.append(f"ğŸ¥ å¥åº·åº¦è¯„ä¼°:")
    
    if avg_ratio > 70:
        health = "ğŸŸ¢ ä¼˜ç§€ - æ­£æ ·æœ¬å æ¯”å¾ˆé«˜ï¼Œç­–ç•¥è´¨é‡å¥½"
    elif avg_ratio > 55:
        health = "ğŸŸ¢ è‰¯å¥½ - æ­£æ ·æœ¬å ä¸»å¯¼"
    elif avg_ratio > 45:
        health = "ğŸŸ¡ ä¸­ç­‰ - æ­£è´Ÿæ ·æœ¬è¾ƒä¸ºå‡è¡¡"
    elif avg_ratio > 30:
        health = "ğŸŸ  åä½ - è´Ÿæ ·æœ¬åå¤š"
    else:
        health = "ğŸ”´ è¾ƒå·® - è´Ÿæ ·æœ¬å ä¸»å¯¼ï¼Œå»ºè®®æ£€æŸ¥ç­–ç•¥"
    
    analysis.append(f"   çŠ¶æ€: {health}")
    analysis.append(f"   å½“å‰å æ¯”: {last_ratio:.2f}%")
    analysis.append("")
    
    ratio_std = ratio_df['ratio'].std()
    analysis.append(f"ğŸ“‰ ç¨³å®šæ€§:")
    analysis.append(f"   æ ‡å‡†å·®: {ratio_std:.2f}%")
    
    if ratio_std < 5:
        stability = "ç¨³å®šæ€§å¾ˆå¥½"
    elif ratio_std < 10:
        stability = "ç¨³å®šæ€§è‰¯å¥½"
    else:
        stability = "æ³¢åŠ¨è¾ƒå¤§"
    analysis.append(f"   è¯„ä¼°: {stability}")
    
    analysis.append("")
    analysis.append("=" * 60)
    
    return "\n".join(analysis)

def analyze_validation_metrics(val_df: pd.DataFrame) -> str:
    """åˆ†æéªŒè¯é›†æŒ‡æ ‡"""
    analysis = []
    analysis.append("=" * 60)
    analysis.append("ğŸ” éªŒè¯é›†æŒ‡æ ‡åˆ†æ")
    analysis.append("=" * 60)
    analysis.append("")
    
    if val_df.empty:
        analysis.append("âš ï¸  æœªæ‰¾åˆ°éªŒè¯é›†æ•°æ®")
        analysis.append("")
        analysis.append("æç¤º: éªŒè¯é›†æ•°æ®é€šå¸¸åœ¨è®­ç»ƒè¿‡ç¨‹ä¸­å®šæœŸç”Ÿæˆ")
        analysis.append("=" * 60)
        return "\n".join(analysis)
    
    analysis.append(f"ğŸ“‹ åŸºæœ¬ä¿¡æ¯:")
    analysis.append(f"   éªŒè¯æ¬¡æ•°: {len(val_df)}")
    analysis.append(f"   éªŒè¯æ­¥æ•°: {val_df['step'].tolist()}")
    analysis.append("")
    
    score_mean = val_df['score'].mean()
    score_std = val_df['score'].std()
    score_trend = val_df['score'].iloc[-1] - val_df['score'].iloc[0] if len(val_df) > 1 else 0
    
    analysis.append(f"ğŸ“Š ScoreæŒ‡æ ‡:")
    analysis.append(f"   å¹³å‡åˆ†æ•°: {score_mean:>8.4f}")
    analysis.append(f"   æ ‡å‡†å·®:   {score_std:>8.4f}")
    analysis.append(f"   è¶‹åŠ¿å˜åŒ–: {score_trend:>+8.4f}")
    
    if score_mean > 0.5:
        score_eval = "âœ… éªŒè¯é›†è¡¨ç°ä¼˜ç§€"
    elif score_mean > 0:
        score_eval = "ğŸŸ¢ éªŒè¯é›†è¡¨ç°è‰¯å¥½"
    elif score_mean > -0.3:
        score_eval = "ğŸŸ¡ éªŒè¯é›†è¡¨ç°ä¸€èˆ¬"
    else:
        score_eval = "âš ï¸  éªŒè¯é›†è¡¨ç°è¾ƒå·®"
    analysis.append(f"   è¯„ä¼°: {score_eval}")
    analysis.append("")
    
    if 'reward' in val_df.columns:
        reward_mean = val_df['reward'].mean()
        reward_trend = val_df['reward'].iloc[-1] - val_df['reward'].iloc[0] if len(val_df) > 1 else 0
        
        analysis.append(f"ğŸ RewardæŒ‡æ ‡:")
        analysis.append(f"   å¹³å‡å¥–åŠ±: {reward_mean:>8.4f}")
        analysis.append(f"   è¶‹åŠ¿å˜åŒ–: {reward_trend:>+8.4f}")
        analysis.append("")
    
    if 'acc' in val_df.columns:
        acc_mean = val_df['acc'].mean()
        acc_trend = val_df['acc'].iloc[-1] - val_df['acc'].iloc[0] if len(val_df) > 1 else 0
        
        analysis.append(f"âœ… å‡†ç¡®ç‡æŒ‡æ ‡:")
        analysis.append(f"   å¹³å‡å‡†ç¡®ç‡: {acc_mean:>8.4f}")
        analysis.append(f"   è¶‹åŠ¿å˜åŒ–:   {acc_trend:>+8.4f}")
        
        if acc_mean > 0.7:
            acc_eval = "âœ… å‡†ç¡®ç‡å¾ˆé«˜"
        elif acc_mean > 0.5:
            acc_eval = "ğŸŸ¢ å‡†ç¡®ç‡è‰¯å¥½"
        else:
            acc_eval = "ğŸŸ¡ å‡†ç¡®ç‡æœ‰æå‡ç©ºé—´"
        analysis.append(f"   è¯„ä¼°: {acc_eval}")
        analysis.append("")
    
    analysis.append(f"ğŸ¯ æ•´ä½“è¯„ä¼°:")
    
    if score_trend > 0.1:
        overall = "âœ… æ¨¡å‹åœ¨éªŒè¯é›†ä¸ŠæŒç»­æ”¹è¿›ï¼Œè®­ç»ƒæ•ˆæœæ˜¾è‘—"
    elif score_trend > 0:
        overall = "ğŸŸ¢ æ¨¡å‹ç¨³æ­¥æå‡"
    elif score_trend > -0.1:
        overall = "ğŸŸ¡ æ¨¡å‹è¡¨ç°ç¨³å®š"
    else:
        overall = "âš ï¸  æ¨¡å‹åœ¨éªŒè¯é›†ä¸Šè¡¨ç°ä¸‹é™ï¼Œå»ºè®®æ£€æŸ¥"
    
    analysis.append(f"   {overall}")
    
    analysis.append("")
    analysis.append("=" * 60)
    
    return "\n".join(analysis)

def plot_score_trend(df: pd.DataFrame, val_df: pd.DataFrame = None) -> plt.Figure:
    """ç»˜åˆ¶Scoreè¶‹åŠ¿å›¾"""
    fig, ax = plt.subplots(figsize=(14, 6))
    
    df_agg = df.groupby('step')['score'].agg(['mean', 'std', 'count']).reset_index()
    
    # ä¸»æ›²çº¿
    ax.plot(df_agg['step'], df_agg['mean'], 'b-', linewidth=2, label='Train Score (Mean)', alpha=0.8)
    
    # æ ‡å‡†å·®é˜´å½±
    if len(df_agg) > 0:
        ax.fill_between(df_agg['step'], 
                        df_agg['mean'] - df_agg['std'], 
                        df_agg['mean'] + df_agg['std'],
                        alpha=0.2, color='blue', label='Â±1 Std Dev')
    
    # æ»‘åŠ¨å¹³å‡
    window = max(3, len(df_agg) // 20)
    if len(df_agg) >= window:
        df_agg['ma'] = df_agg['mean'].rolling(window=window, center=True).mean()
        ax.plot(df_agg['step'], df_agg['ma'], 'darkblue', linewidth=3, 
                linestyle='--', label=f'Moving Avg (window={window})')
    
    # éªŒè¯ç‚¹
    if val_df is not None and not val_df.empty:
        ax.scatter(val_df['step'], val_df['score'], color='red', s=150, 
                  marker='*', label='Validation', zorder=5, edgecolors='darkred', linewidths=2)
    
    # è¶‹åŠ¿çº¿
    if len(df_agg) > 1:
        z = np.polyfit(df_agg['step'], df_agg['mean'], 1)
        p = np.poly1d(z)
        ax.plot(df_agg['step'], p(df_agg['step']), "g--", alpha=0.5, linewidth=2, 
                label=f'Trend Line (slope={z[0]:.4f})')
    
    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5, linewidth=1)
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Score', fontsize=12, fontweight='bold')
    ax.set_title('Training Score Trend', fontsize=14, fontweight='bold')
    ax.legend(loc='best', fontsize=10)
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_score_distribution(df: pd.DataFrame) -> plt.Figure:
    """ç»˜åˆ¶Scoreåˆ†å¸ƒå›¾"""
    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(14, 5))
    
    scores = df['score'].values
    
    # ç›´æ–¹å›¾
    ax1.hist(scores, bins=50, color='skyblue', edgecolor='black', alpha=0.7)
    ax1.axvline(x=np.mean(scores), color='red', linestyle='--', linewidth=2, 
                label=f'Mean={np.mean(scores):.3f}')
    ax1.axvline(x=np.median(scores), color='green', linestyle='--', linewidth=2,
                label=f'Median={np.median(scores):.3f}')
    ax1.axvline(x=0, color='gray', linestyle='-', alpha=0.5, linewidth=1)
    ax1.set_xlabel('Score', fontsize=12)
    ax1.set_ylabel('Frequency', fontsize=12)
    ax1.set_title('Score Distribution Histogram', fontsize=13, fontweight='bold')
    ax1.legend()
    ax1.grid(True, alpha=0.3, axis='y')
    
    # ç®±çº¿å›¾
    df_sorted = df.sort_values('step')
    steps = df_sorted['step'].unique()
    step_sample = steps[::max(1, len(steps)//15)]
    
    box_data = [df[df['step'] == s]['score'].values for s in step_sample]
    bp = ax2.boxplot(box_data, labels=[str(int(s)) for s in step_sample], patch_artist=True)
    
    for patch in bp['boxes']:
        patch.set_facecolor('lightblue')
        patch.set_alpha(0.7)
    
    ax2.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    ax2.set_xlabel('Training Step', fontsize=12)
    ax2.set_ylabel('Score', fontsize=12)
    ax2.set_title('Score Distribution by Step (Boxplot)', fontsize=13, fontweight='bold')
    ax2.grid(True, alpha=0.3, axis='y')
    plt.setp(ax2.xaxis.get_majorticklabels(), rotation=45)
    
    plt.tight_layout()
    return fig

def plot_accuracy_trend(df: pd.DataFrame, val_df: pd.DataFrame = None) -> plt.Figure:
    """ç»˜åˆ¶Accuracyè¶‹åŠ¿å›¾"""
    fig, ax = plt.subplots(figsize=(14, 6))
    
    if 'acc' not in df.columns or df['acc'].isna().all():
        ax.text(0.5, 0.5, 'No Accuracy Data Found', 
                ha='center', va='center', fontsize=20, color='gray')
        ax.axis('off')
        return fig
    
    df_agg = df.groupby('step')['acc'].agg(['mean', 'std']).reset_index()
    
    ax.plot(df_agg['step'], df_agg['mean'], 'g-', linewidth=2, label='Train Accuracy', alpha=0.8)
    ax.fill_between(df_agg['step'], 
                    df_agg['mean'] - df_agg['std'], 
                    df_agg['mean'] + df_agg['std'],
                    alpha=0.2, color='green', label='Â±1 Std Dev')
    
    if val_df is not None and not val_df.empty and 'acc' in val_df.columns:
        ax.scatter(val_df['step'], val_df['acc'], color='orange', s=150,
                  marker='s', label='Validation Accuracy', zorder=5, edgecolors='darkorange', linewidths=2)
    
    ax.axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Accuracy', fontsize=12, fontweight='bold')
    ax.set_title('Training Accuracy Trend', fontsize=14, fontweight='bold')
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_positive_ratio(df: pd.DataFrame) -> plt.Figure:
    """ç»˜åˆ¶æ­£è´Ÿæ ·æœ¬å æ¯”"""
    fig, ax = plt.subplots(figsize=(14, 6))
    
    df['is_positive'] = df['score'] > 0
    ratio_df = df.groupby('step')['is_positive'].agg(['sum', 'count']).reset_index()
    ratio_df['ratio'] = ratio_df['sum'] / ratio_df['count'] * 100
    
    ax.plot(ratio_df['step'], ratio_df['ratio'], 'purple', linewidth=2.5, marker='o', markersize=6)
    ax.axhline(y=50, color='gray', linestyle='--', alpha=0.5, linewidth=2, label='50% Baseline')
    ax.fill_between(ratio_df['step'], ratio_df['ratio'], 50, 
                    where=(ratio_df['ratio'] >= 50), alpha=0.3, color='green', label='Above 50%')
    ax.fill_between(ratio_df['step'], ratio_df['ratio'], 50,
                    where=(ratio_df['ratio'] < 50), alpha=0.3, color='red', label='Below 50%')
    
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Positive Sample Ratio (%)', fontsize=12, fontweight='bold')
    ax.set_title('Positive Sample Ratio Trend', fontsize=14, fontweight='bold')
    ax.set_ylim([0, 100])
    ax.legend()
    ax.grid(True, alpha=0.3)
    
    plt.tight_layout()
    return fig

def plot_validation_metrics(val_df: pd.DataFrame) -> plt.Figure:
    """ç»˜åˆ¶ValidationæŒ‡æ ‡"""
    if val_df.empty:
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.text(0.5, 0.5, 'No Validation Data Found', 
                ha='center', va='center', fontsize=20, color='gray')
        ax.axis('off')
        return fig
    
    fig, axes = plt.subplots(1, 3, figsize=(16, 5))
    
    # Score
    axes[0].plot(val_df['step'], val_df['score'], 'b-o', linewidth=2, markersize=8)
    axes[0].axhline(y=0, color='gray', linestyle='--', alpha=0.5)
    axes[0].set_xlabel('Step', fontsize=11)
    axes[0].set_ylabel('Score', fontsize=11)
    axes[0].set_title('Validation Score', fontsize=12, fontweight='bold')
    axes[0].grid(True, alpha=0.3)
    
    # Reward
    if 'reward' in val_df.columns:
        axes[1].plot(val_df['step'], val_df['reward'], 'purple', marker='s', 
                    linewidth=2, markersize=8)
        axes[1].axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        axes[1].set_xlabel('Step', fontsize=11)
        axes[1].set_ylabel('Reward', fontsize=11)
        axes[1].set_title('Validation Reward', fontsize=12, fontweight='bold')
        axes[1].grid(True, alpha=0.3)
    else:
        axes[1].text(0.5, 0.5, 'No Reward Data', ha='center', va='center', fontsize=14, color='gray')
        axes[1].axis('off')
    
    # Accuracy
    if 'acc' in val_df.columns:
        axes[2].plot(val_df['step'], val_df['acc'], 'g-^', linewidth=2, markersize=8)
        axes[2].axhline(y=0, color='gray', linestyle='--', alpha=0.5)
        axes[2].set_xlabel('Step', fontsize=11)
        axes[2].set_ylabel('Accuracy', fontsize=11)
        axes[2].set_title('Validation Accuracy', fontsize=12, fontweight='bold')
        axes[2].grid(True, alpha=0.3)
    else:
        axes[2].text(0.5, 0.5, 'No Accuracy Data', ha='center', va='center', fontsize=14, color='gray')
        axes[2].axis('off')
    
    plt.tight_layout()
    return fig

def generate_statistics(df: pd.DataFrame, val_df: pd.DataFrame = None) -> str:
    """ç”Ÿæˆç»Ÿè®¡ä¿¡æ¯æ–‡æœ¬"""
    stats = []
    stats.append("=" * 60)
    stats.append("ğŸ“Š è®­ç»ƒç»Ÿè®¡ä¿¡æ¯æ€»è§ˆ")
    stats.append("=" * 60)
    stats.append("")
    
    stats.append(f"ğŸ”¢ åŸºæœ¬ä¿¡æ¯:")
    stats.append(f"   æ€»è®­ç»ƒæ­¥æ•°: {df['step'].max()}")
    stats.append(f"   æ€»æ ·æœ¬æ•°:   {len(df)}")
    stats.append(f"   æ¯æ­¥æ ·æœ¬æ•°: {len(df) / df['step'].nunique():.1f} (å¹³å‡)")
    stats.append("")
    
    scores = df['score'].values
    stats.append("ğŸ“ˆ åˆ†æ•°ç»Ÿè®¡:")
    stats.append(f"   å‡å€¼:     {np.mean(scores):>8.4f}")
    stats.append(f"   æ ‡å‡†å·®:   {np.std(scores):>8.4f}")
    stats.append(f"   ä¸­ä½æ•°:   {np.median(scores):>8.4f}")
    stats.append(f"   æœ€å°å€¼:   {np.min(scores):>8.4f}")
    stats.append(f"   æœ€å¤§å€¼:   {np.max(scores):>8.4f}")
    stats.append(f"   Q25:      {np.percentile(scores, 25):>8.4f}")
    stats.append(f"   Q75:      {np.percentile(scores, 75):>8.4f}")
    stats.append("")
    
    pos_count = np.sum(scores > 0)
    neg_count = np.sum(scores < 0)
    zero_count = np.sum(scores == 0)
    stats.append("ğŸ¯ æ ·æœ¬åˆ†å¸ƒ:")
    stats.append(f"   æ­£æ ·æœ¬: {pos_count:>6} ({pos_count/len(scores)*100:>5.1f}%)")
    stats.append(f"   è´Ÿæ ·æœ¬: {neg_count:>6} ({neg_count/len(scores)*100:>5.1f}%)")
    stats.append(f"   é›¶å€¼:   {zero_count:>6} ({zero_count/len(scores)*100:>5.1f}%)")
    stats.append("")
    
    if 'acc' in df.columns:
        accs = df['acc'].dropna().values
        if len(accs) > 0:
            stats.append("âœ… å‡†ç¡®ç‡ç»Ÿè®¡:")
            stats.append(f"   å¹³å‡å€¼: {np.mean(accs):>8.4f}")
            stats.append(f"   æœ€ç»ˆå€¼: {df.groupby('step')['acc'].mean().iloc[-1]:>8.4f}")
            stats.append("")
    
    early_scores = scores[:len(scores)//5]
    recent_scores = scores[-len(scores)//5:]
    change = np.mean(recent_scores) - np.mean(early_scores)
    
    stats.append("ğŸ“Š è¶‹åŠ¿åˆ†æ:")
    stats.append(f"   åˆæœŸå¹³å‡ (å‰20%): {np.mean(early_scores):>8.4f}")
    stats.append(f"   è¿‘æœŸå¹³å‡ (å20%): {np.mean(recent_scores):>8.4f}")
    
    if change > 0.01:
        trend_indicator = "ğŸ“ˆ (æ”¹è¿›ä¸­)"
    elif change < -0.01:
        trend_indicator = "ğŸ“‰ (ä¸‹é™ä¸­)"
    else:
        trend_indicator = "â¡ï¸  (ç¨³å®š)"
    
    stats.append(f"   å˜åŒ–é‡:           {change:>8.4f} {trend_indicator}")
    stats.append("")
    
    if val_df is not None and not val_df.empty:
        stats.append("ğŸ” éªŒè¯é›†ç»Ÿè®¡:")
        stats.append(f"   éªŒè¯æ¬¡æ•°: {len(val_df)}")
        stats.append(f"   å¹³å‡åˆ†æ•°: {val_df['score'].mean():>8.4f}")
        if 'reward' in val_df.columns:
            stats.append(f"   å¹³å‡å¥–åŠ±: {val_df['reward'].mean():>8.4f}")
        if 'acc' in val_df.columns:
            stats.append(f"   å¹³å‡å‡†ç¡®ç‡: {val_df['acc'].mean():>8.4f}")
        stats.append("")
    
    stats.append("ğŸ¥ è®­ç»ƒå¥åº·åº¦è¯„ä¼°:")
    recent_avg = np.mean(recent_scores)
    
    if recent_avg > 0.5:
        health = "ğŸŸ¢ ä¼˜ç§€ - æ¨¡å‹å­¦ä¹ æ•ˆæœå¾ˆå¥½"
    elif recent_avg > 0:
        health = "ğŸŸ¡ è‰¯å¥½ - è®­ç»ƒè¿›å±•é¡ºåˆ©"
    elif recent_avg > -0.3:
        health = "ğŸŸ  ä¸€èˆ¬ - éœ€è¦å…³æ³¨"
    else:
        health = "ğŸ”´ è¾ƒå·® - å»ºè®®è°ƒæ•´è¶…å‚æ•°"
    
    stats.append(f"   çŠ¶æ€: {health}")
    stats.append(f"   è¿‘æœŸåˆ†æ•°: {recent_avg:.4f}")
    stats.append("")
    
    stats.append("=" * 60)
    
    return "\n".join(stats)

def analyze_training(task_name: str, plots: List[str]) -> Tuple:
    """ä¸»åˆ†æå‡½æ•°"""
    if not task_name:
        empty_msg = "âš ï¸ è¯·é€‰æ‹©ä¸€ä¸ªè®­ç»ƒä»»åŠ¡"
        return None, empty_msg, None, empty_msg, None, empty_msg, None, empty_msg, None, empty_msg, empty_msg, empty_msg
    
    try:
        df = load_rollout_data(task_name)
        val_df = load_validation_data(task_name)
        
        if df.empty:
            error_msg = f"âŒ æœªæ‰¾åˆ°ä»»åŠ¡æ•°æ®: {task_name}"
            return None, error_msg, None, error_msg, None, error_msg, None, error_msg, None, error_msg, error_msg, error_msg
        
        stats_text = generate_statistics(df, val_df)
        recommendation_text = recommend_best_checkpoint(task_name, df, val_df)  # âœ… ä¼ å…¥task_name
        
        plot1, analysis1 = (None, "")
        plot2, analysis2 = (None, "")
        plot3, analysis3 = (None, "")
        plot4, analysis4 = (None, "")
        plot5, analysis5 = (None, "")
        
        if "åˆ†æ•°è¶‹åŠ¿" in plots:
            plot1 = plot_score_trend(df, val_df)
            analysis1 = analyze_score_trend(df, val_df)
        
        if "åˆ†æ•°åˆ†å¸ƒ" in plots:
            plot2 = plot_score_distribution(df)
            analysis2 = analyze_score_distribution(df)
        
        if "å‡†ç¡®ç‡è¶‹åŠ¿" in plots:
            plot3 = plot_accuracy_trend(df, val_df)
            analysis3 = analyze_accuracy_trend(df, val_df)
        
        if "æ­£æ ·æœ¬å æ¯”" in plots:
            plot4 = plot_positive_ratio(df)
            analysis4 = analyze_positive_ratio(df)
        
        if "éªŒè¯æŒ‡æ ‡" in plots:
            plot5 = plot_validation_metrics(val_df)
            analysis5 = analyze_validation_metrics(val_df)
        
        return plot1, analysis1, plot2, analysis2, plot3, analysis3, plot4, analysis4, plot5, analysis5, stats_text, recommendation_text
        
    except Exception as e:
        import traceback
        error_msg = f"âŒ é”™è¯¯: {str(e)}\n\n{traceback.format_exc()}"
        return None, error_msg, None, error_msg, None, error_msg, None, error_msg, None, error_msg, error_msg, error_msg

def create_interface():
    """åˆ›å»ºGradioç•Œé¢"""
    
    with gr.Blocks(title="è®­ç»ƒç›‘æ§å°", theme=gr.themes.Soft()) as demo:
        gr.Markdown("""
        # ğŸ¯ è®­ç»ƒæ—¥å¿—ç›‘æ§å°
        ### å®æ—¶è®­ç»ƒæ—¥å¿—å¯è§†åŒ–åˆ†æå·¥å…·
        """)
        
        with gr.Row():
            with gr.Column(scale=1):
                gr.Markdown("### ğŸ”§ æ§åˆ¶é¢æ¿")
                
                task_dropdown = gr.Dropdown(
                    choices=scan_training_tasks(),
                    label="ğŸ“ é€‰æ‹©è®­ç»ƒä»»åŠ¡",
                    info="é€‰æ‹©ä¸€ä¸ªè®­ç»ƒä»»åŠ¡è¿›è¡Œåˆ†æ",
                    interactive=True
                )
                
                refresh_btn = gr.Button("ğŸ”„ åˆ·æ–°ä»»åŠ¡åˆ—è¡¨", size="sm")
                
                plot_checkboxes = gr.CheckboxGroup(
                    choices=[
                        "åˆ†æ•°è¶‹åŠ¿",
                        "åˆ†æ•°åˆ†å¸ƒ", 
                        "å‡†ç¡®ç‡è¶‹åŠ¿",
                        "æ­£æ ·æœ¬å æ¯”",
                        "éªŒè¯æŒ‡æ ‡"
                    ],
                    value=["åˆ†æ•°è¶‹åŠ¿", "åˆ†æ•°åˆ†å¸ƒ"],
                    label="ğŸ“Š é€‰æ‹©è¦æ˜¾ç¤ºçš„å›¾è¡¨",
                    info="å‹¾é€‰ä½ æƒ³æŸ¥çœ‹çš„å¯è§†åŒ–å›¾è¡¨"
                )
                
                analyze_btn = gr.Button("ğŸš€ å¼€å§‹åˆ†æ", variant="primary", size="lg")
                
                gr.Markdown("""
                ---
                **ä½¿ç”¨æç¤ºï¼š**
                - ä»ä¸‹æ‹‰èœå•é€‰æ‹©è®­ç»ƒä»»åŠ¡
                - å‹¾é€‰æƒ³è¦æŸ¥çœ‹çš„å›¾è¡¨ç±»å‹
                - ç‚¹å‡»"å¼€å§‹åˆ†æ"ç”Ÿæˆå¯è§†åŒ–
                - æ¯ä¸ªå›¾è¡¨ä¸‹æ–¹éƒ½æœ‰è¯¦ç»†åˆ†æ
                - **æ–°å¢ï¼šæ¨¡å‹æ¨è** ğŸ†
                """)
            
            with gr.Column(scale=3):
                gr.Markdown("### ğŸ“ˆ å¯è§†åŒ–ç»“æœ")
                
                with gr.Tabs():
                    with gr.Tab("ğŸ† æ¨¡å‹æ¨è"):
                        recommendation_output = gr.Textbox(
                            label="æ£€æŸ¥ç‚¹æ¨è",
                            lines=35,
                            max_lines=50,
                            show_label=True,
                            elem_classes="monospace",
                            interactive=False,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("ğŸ“Š ç»Ÿè®¡æ€»è§ˆ"):
                        stats_output = gr.Textbox(
                            label="è®­ç»ƒç»Ÿè®¡ä¿¡æ¯",
                            lines=35,
                            max_lines=50,
                            show_label=False,
                            elem_classes="monospace",
                            interactive=False,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("ğŸ“ˆ åˆ†æ•°è¶‹åŠ¿"):
                        plot1 = gr.Plot(label="åˆ†æ•°è¶‹åŠ¿å›¾")
                        analysis1 = gr.Textbox(
                            label="è¶‹åŠ¿åˆ†æ",
                            lines=25,
                            max_lines=40,
                            show_label=True,
                            interactive=False,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("ğŸ“Š åˆ†æ•°åˆ†å¸ƒ"):
                        plot2 = gr.Plot(label="åˆ†æ•°åˆ†å¸ƒå›¾")
                        analysis2 = gr.Textbox(
                            label="åˆ†å¸ƒåˆ†æ",
                            lines=25,
                            max_lines=40,
                            show_label=True,
                            interactive=False,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("âœ… å‡†ç¡®ç‡"):
                        plot3 = gr.Plot(label="å‡†ç¡®ç‡è¶‹åŠ¿å›¾")
                        analysis3 = gr.Textbox(
                            label="å‡†ç¡®ç‡åˆ†æ",
                            lines=25,
                            max_lines=40,
                            show_label=True,
                            interactive=False,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("âš–ï¸ æ­£æ ·æœ¬å æ¯”"):
                        plot4 = gr.Plot(label="æ­£æ ·æœ¬æ¯”ä¾‹å›¾")
                        analysis4 = gr.Textbox(
                            label="å æ¯”åˆ†æ",
                            lines=25,
                            max_lines=40,
                            show_label=True,
                            interactive=False,
                            show_copy_button=True
                        )
                    
                    with gr.Tab("ğŸ” éªŒè¯é›†"):
                        plot5 = gr.Plot(label="éªŒè¯é›†æŒ‡æ ‡å›¾")
                        analysis5 = gr.Textbox(
                            label="éªŒè¯é›†åˆ†æ",
                            lines=25,
                            max_lines=40,
                            show_label=True,
                            interactive=False,
                            show_copy_button=True
                        )
        
        def refresh_tasks():
            return gr.Dropdown(choices=scan_training_tasks())
        
        refresh_btn.click(
            fn=refresh_tasks,
            outputs=task_dropdown
        )
        
        analyze_btn.click(
            fn=analyze_training,
            inputs=[task_dropdown, plot_checkboxes],
            outputs=[plot1, analysis1, plot2, analysis2, plot3, analysis3, 
                    plot4, analysis4, plot5, analysis5, stats_output, recommendation_output]
        )
        
        gr.Markdown("""
        ---
        ğŸ’¡ **å…³äº**: æ­¤å·¥å…·ç”¨äºåˆ†æRLHFè®­ç»ƒæ—¥å¿—ï¼ˆrolloutå’Œvalidationæ•°æ®ï¼‰  
        ğŸ“ **æ ¹ç›®å½•**: `/lpai/volumes/base-mindgpt-ali-sh-mix/zhaojiale/why_ask/output_models`  
        ğŸ¨ **ç‰¹æ€§**: å®æ—¶å¯è§†åŒ–ã€æ™ºèƒ½åˆ†æã€å¤šç»´åº¦è¯„ä¼°ã€è‡ªåŠ¨æ¨èæœ€ä½³checkpoint
        """)
    
    return demo

if __name__ == "__main__":
    print("ğŸš€ å¯åŠ¨è®­ç»ƒç›‘æ§å°...")
    ROOT_DIR = Path("/lpai/volumes/base-mindgpt-ali-sh-mix/zhaojiale/why_ask/output_models")
    print(f"ğŸ“‚ æ‰«æç›®å½•: {ROOT_DIR}")
    
    tasks = scan_training_tasks()
    print(f"âœ… å‘ç° {len(tasks)} ä¸ªè®­ç»ƒä»»åŠ¡")
    
    demo = create_interface()
    
    demo.launch(
        server_name="0.0.0.0",
        server_port=7860,
        share=False,
        show_error=True
    )